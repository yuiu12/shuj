检索增强生成 （RAG） 在 LLM 的工作流程中增加了一个检索步骤，使其能够在回答问题和查询时从其他来源（如私人文档）查询相关数据 [1]。此工作流程不需要对其他文档的 LLM 进行昂贵的培训或微调。文档被拆分为片段，然后进行索引，通常使用 ML 生成的紧凑向量表示（嵌入）。在此嵌入空间中，具有相似内容的 snippet 将彼此靠近。

RAG 应用程序将用户提供的问题投影到嵌入空间中，以根据它们与问题的距离检索相关文档片段。LLM 可以使用检索到的信息来回答查询，并通过将代码片段作为参考来证实其结论。


RAG 应用程序的评估具有挑战性 [2]。存在不同的方法：一方面，有些方法必须由开发人员提供作为基本事实的答案;另一方面，答案（和问题）也可以由另一个 LLM 生成。用于 LLM 支持的答案的最大开源系统之一是 Ragas [4]（Retrieval-Augmented Generation Assessment），它提供

根据文档生成测试数据的方法
基于不同指标的评估，用于逐个和端到端地评估检索和生成步骤。




